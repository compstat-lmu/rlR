<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Play Atari Games â€¢ rlR</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Play Atari Games">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">rlR</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-file-text-o"></span>
     
    Topics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/define_custom_environments.html">Specify Custom Environment</a>
    </li>
    <li>
      <a href="../articles/repeated_experiment.html">Repeated Experiment</a>
    </li>
    <li>
      <a href="../articles/customized_brain_mountainCar.html">Customize Neural Network Functional Approximator</a>
    </li>
    <li>
      <a href="../articles/play_atari_games.html">Play Atari Games</a>
    </li>
    <li>
      <a href="../articles/table_learning.html">Tabular Learning</a>
    </li>
  </ul>
</li>
<li>
  <a href="../reference/index.html">
    <span class="fa fa-book"></span>
     
    Reference
  </a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/smilesun/rlR">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Play Atari Games</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/smilesun/rlR/blob/master/vignettes/vignettes/play_atari_games.Rmd"><code>vignettes/vignettes/play_atari_games.Rmd</code></a></small>
      <div class="hidden name"><code>play_atari_games.Rmd</code></div>

    </div>

    
    
<div id="rlr-play-atari-games" class="section level1">
<h1 class="hasAnchor">
<a href="#rlr-play-atari-games" class="anchor"></a>rlR: play Atari games</h1>
<div id="convolutional-neural-network-structure" class="section level2">
<h2 class="hasAnchor">
<a href="#convolutional-neural-network-structure" class="anchor"></a>Convolutional Neural Network Structure</h2>
</div>
<div id="atari-environment" class="section level2">
<h2 class="hasAnchor">
<a href="#atari-environment" class="anchor"></a>Atari Environment</h2>
<p>For Atari Games, it makes more since to stack several recent frames since the agent need to know what is happening and with only one frame it is hard to judge the current situation. So we have the <code>observ_stack_len</code> parameter.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rlR)
env =<span class="st"> </span><span class="kw"><a href="../reference/makeGymEnv.html">makeGymEnv</a></span>(<span class="st">"Seaquest-v0"</span>, <span class="dt">observ_stack_len =</span> 4L, <span class="dt">state_preprocess =</span> <span class="kw">list</span>(<span class="dt">fun =</span> rlR<span class="op">:::</span>subsample))</code></pre></div>
<p>Since the input state space is RGB image, we would like to down sample the state space by the following function</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rlR<span class="op">:::</span>subsample
## function (state) 
## {
##     I = state[seq(30L, 210L, 3L), seq(1L, 160L, 2L), ]
##     I = 0.299 * I[, , 1L] + 0.587 * I[, , 2L] + 0.114 * I[, , 
##         3L]
##     res = array_reshape(I, c(dim(I), 1L))
##     return(res)
## }
## &lt;environment: namespace:rlR&gt;</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">env<span class="op">$</span><span class="kw">overview</span>()
## 
## action cnt: 18 
## state original dim: 210, 160, 3 
## state dim after preprocessing: 61, 80, 1 
## with stacking: 61, 80, 4 
## discrete action</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">env<span class="op">$</span><span class="kw">snapshot</span>(<span class="dt">preprocess =</span> T)
env<span class="op">$</span><span class="kw">snapshot</span>(<span class="dt">preprocess =</span> F)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">conf =<span class="st"> </span><span class="kw"><a href="../reference/getDefaultConf.html">getDefaultConf</a></span>(<span class="st">"AgentFDQN"</span>)</code></pre></div>
<p>The rlR package has been optimized to handle replay memory in a very efficient way, to ensure performance, you could also use the following parameters which has a bigger replay memory.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">conf<span class="op">$</span><span class="kw">set</span>(<span class="dt">replay.batchsize =</span> <span class="dv">32</span>, 
  <span class="dt">replay.freq =</span> 1L, 
  <span class="dt">console =</span> <span class="ot">TRUE</span>, 
  <span class="dt">agent.lr.decay =</span> <span class="dv">1</span>, 
  <span class="dt">agent.lr =</span> <span class="fl">0.00025</span>, 
  <span class="dt">agent.update.target.freq =</span> <span class="fl">1e4</span>,
  <span class="dt">replay.memname =</span> <span class="st">"Png"</span>, 
  <span class="dt">render =</span> F, 
  <span class="dt">policy.minEpsilon =</span> <span class="fl">0.1</span>, 
  <span class="dt">agent.start.learn =</span> 5e4L, 
  <span class="dt">policy.aneal.steps =</span> <span class="fl">1e6</span>,
  <span class="dt">replay.mem.size =</span> <span class="fl">1e6</span>, 
  <span class="dt">log =</span> <span class="ot">FALSE</span>, 
  <span class="dt">agent.clip.td =</span> <span class="ot">TRUE</span>, 
  <span class="dt">policy.decay.type =</span> <span class="st">"decay_linear"</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">makeCnnCritic =<span class="st"> </span><span class="cf">function</span>(state_dim, act_cnt) {
  <span class="kw">require</span>(<span class="st">"keras"</span>)
  text =<span class="st"> </span><span class="kw">paste</span>(<span class="st">"model &lt;- keras_model_sequential();"</span>,
  <span class="st">'model %&gt;%'</span>,
  <span class="st">' layer_conv_2d(filter = 16, kernel_size = c(8,8), strides = c(4, 4), </span>
<span class="st">  padding = "same", input_shape = state_dim) %&gt;%'</span>,
    <span class="st">'layer_activation("relu") %&gt;%'</span>,
    <span class="st">'layer_conv_2d(filter = 32, kernel_size = c(4,4), strides = c(2, 2)) %&gt;%'</span>,
    <span class="st">'layer_activation("relu") %&gt;%'</span>,
    <span class="st">'layer_flatten() %&gt;%'</span>,
    <span class="st">'layer_dense(256) %&gt;%'</span>,
    <span class="st">'layer_activation("relu") %&gt;%'</span>,
    <span class="st">'layer_dense(act_cnt) %&gt;%'</span>,
    <span class="st">'layer_activation("linear");'</span>,
    <span class="st">'opt &lt;- optimizer_rmsprop(lr = 0.00025);'</span>,
    <span class="st">'model %&gt;% compile(loss = "mse", optimizer = opt, metrics = "accuracy")'</span>)
  model =<span class="st"> </span><span class="kw">eval</span>(<span class="kw">parse</span>(<span class="dt">text =</span> text))
  <span class="kw">return</span>(model)
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">agent =<span class="st"> </span><span class="kw"><a href="../reference/initAgent.html">initAgent</a></span>(<span class="st">"AgentFDQN"</span>, env, conf, <span class="dt">custom_brain =</span> <span class="ot">TRUE</span>)
agent<span class="op">$</span><span class="kw">customizeBrain</span>(<span class="kw">list</span>(<span class="dt">value_fun =</span> makeCnnCritic))
## Loading required package: keras</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">agent<span class="op">$</span><span class="kw">learn</span>(1L)</code></pre></div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li>
<a href="#rlr-play-atari-games">rlR: play Atari games</a><ul class="nav nav-pills nav-stacked">
<li><a href="#convolutional-neural-network-structure">Convolutional Neural Network Structure</a></li>
      <li><a href="#atari-environment">Atari Environment</a></li>
      </ul>
</li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Xudong Sun.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  

  </body>
</html>
